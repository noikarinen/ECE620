{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a155f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "from lifelines import KaplanMeierFitter, LogNormalFitter, WeibullFitter\n",
    "from lifelines.utils import survival_table_from_events\n",
    "from scipy.stats import binom, lognorm, norm, weibull_min\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d1558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10437/2914010790.py:36: UserWarning: The effect of Potentials on other parameters is ignored during prior predictive sampling. This is likely to lead to invalid or biased predictive samples.\n",
      "  idata = pm.sample_prior_predictive()\n",
      "Sampling: [alpha, beta, y_obs]\n",
      "Multiprocess sampling (32 chains in 32 jobs)\n",
      "NUTS: [beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='64000' class='' max='64000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [64000/64000 00:39&lt;00:00 Sampling 32 chains, 341 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 32 chains for 1_000 tune and 1_000 draw iterations (32_000 + 32_000 draws total) took 40 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "There were 341 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "/tmp/ipykernel_10437/2914010790.py:39: UserWarning: The effect of Potentials on other parameters is ignored during posterior predictive sampling. This is likely to lead to invalid or biased predictive samples.\n",
      "  idata.extend(pm.sample_posterior_predictive(idata))\n",
      "Sampling: [y_obs]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='13059' class='' max='32000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.81% [13059/32000 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have data for \"y\" and \"censored\"\n",
    "\n",
    "y = np.array([56]*3000 + [117]*1500 + [266]*1250 + [315]*1150 + [405]*1100 + [501]*1000 +\n",
    "                 [615]*1100 + [704]*1150 + [838]*120 + [901]*130 + [1010]*125 + [1111]*100 +\n",
    "                 [1250]*50 + [1350]*400 + [1500]*300 + [1600]*100 + [1700]*5 + [1870]*3 +\n",
    "                 [2070]*4 + [1550]*1 + [1050]*1 + [1000]*1 + [500]*1 + [350]*1 + [250]*1)\n",
    "\n",
    "censored = np.array([True]*3000 + [True]*1500 + [True]*1250+ [True]*1150 + [True]*1100 + [True]*1000 +\n",
    "                 [True]*1100 + [True]*1150 + [True]*120 + [True]*130 + [True]*125 + [True]*100 +\n",
    "                 [True]*50 + [True]*400 + [True]*300 + [True]*100 + [True]*5 + [True]*3 +\n",
    "                 [True]*4 + [False]*1 + [False]*1 + [False]*1 + [False]*1 + [False]*1 + [False]*1)\n",
    "\n",
    "\n",
    "def weibull_lccdf(y, alpha, beta):\n",
    "    \"\"\"Log complementary cdf of Weibull distribution.\"\"\"\n",
    "    return -((y / beta) ** alpha)\n",
    "\n",
    "priors = {\"beta\": [100, 15000], \"alpha\": [4, 1, 0.02, 8]}\n",
    "priors_informative = {\"beta\": [10000, 500], \"alpha\": [2, 0.5, 0.02, 3]}\n",
    "\n",
    "\n",
    "def make_model(p, info=False):\n",
    "    with pm.Model() as model:\n",
    "        if info:\n",
    "            beta = pm.Normal(\"beta\", p[\"beta\"][0], p[\"beta\"][1])\n",
    "        else:\n",
    "            beta = pm.Uniform(\"beta\", p[\"beta\"][0], p[\"beta\"][1])\n",
    "        alpha = pm.TruncatedNormal(\n",
    "            \"alpha\", p[\"alpha\"][0], p[\"alpha\"][1], lower=p[\"alpha\"][2], upper=p[\"alpha\"][3]\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "        y_obs = pm.Weibull(\"y_obs\", alpha=alpha, beta=beta, observed=y[~censored])\n",
    "        y_cens = pm.Potential(\"y_cens\", weibull_lccdf(y[censored], alpha, beta))\n",
    "        idata = pm.sample_prior_predictive()\n",
    "        #idata.extend(pm.sample(draws=1000,tune=1000, cores=32,random_seed=100, target_accept=0.95))\n",
    "        idata.extend(pm.sample(draws=1000,tune=1000, cores=32,step=pm.NUTS()))\n",
    "        idata.extend(pm.sample_posterior_predictive(idata))\n",
    "\n",
    "    return idata, model\n",
    "\n",
    "idata, model = make_model(priors)\n",
    "idata_informative, model = make_model(priors_informative, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da41f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be13982",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata_informative);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(sample):\n",
    "    # convert sample to a numpy array, if it isn't already\n",
    "    sample = np.atleast_1d(sample)\n",
    "\n",
    "    # find the unique values and their corresponding counts\n",
    "    quantiles, counts = np.unique(sample, return_counts=True)\n",
    "\n",
    "    # take the cumulative sum of the counts and divide by the sample size to\n",
    "    # get the cumulative probabilities between 0 and 1\n",
    "    cumprob = np.cumsum(counts).astype(np.double) / sample.size\n",
    "\n",
    "    return quantiles, cumprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_draws = az.extract(idata, num_samples=1000)[[\"alpha\", \"beta\"]]\n",
    "alphas = joint_draws[\"alpha\"].values\n",
    "betas = joint_draws[\"beta\"].values\n",
    "\n",
    "joint_draws_informative = az.extract(idata_informative, num_samples=1000)[[\"alpha\", \"beta\"]]\n",
    "alphas_informative = joint_draws_informative[\"alpha\"].values\n",
    "betas_informative = joint_draws_informative[\"beta\"].values\n",
    "\n",
    "draws = pm.draw(pm.Weibull.dist(alpha=np.mean(alphas), beta=np.mean(betas)), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot for ax (first plot)\n",
    "hist_data = []\n",
    "for i in range(1000):\n",
    "    draws = pm.draw(pm.Weibull.dist(alpha=alphas[i], beta=betas[i]), 1000)\n",
    "    qe, pe = ecdf(draws)\n",
    "    lkup = dict(zip(pe, qe))\n",
    "    hist_data.append([lkup[0.1], lkup[0.05]])\n",
    "    ax.plot(qe, pe, color=\"slateblue\", alpha=0.1)\n",
    "\n",
    "hist_data_info = []\n",
    "for i in range(1000):\n",
    "    draws = pm.draw(pm.Weibull.dist(alpha=alphas_informative[i], beta=betas_informative[i]), 1000)\n",
    "    qe, pe = ecdf(draws)\n",
    "    lkup = dict(zip(pe, qe))\n",
    "    hist_data_info.append([lkup[0.1], lkup[0.05]])\n",
    "    ax.plot(qe, pe, color=\"pink\", alpha=0.1)\n",
    "\n",
    "hist_data = pd.DataFrame(hist_data, columns=[\"p10\", \"p05\"])\n",
    "hist_data_info = pd.DataFrame(hist_data_info, columns=[\"p10\", \"p05\"])\n",
    "\n",
    "draws = pm.draw(pm.Weibull.dist(alpha=np.mean(alphas), beta=np.mean(betas)), 1000)\n",
    "qe, pe = ecdf(draws)\n",
    "ax.plot(qe, pe, color=\"purple\", label=\"Expected CDF Uninformative Prior\")\n",
    "\n",
    "draws = pm.draw(pm.Weibull.dist(alpha=np.mean(alphas_informative), beta=np.mean(betas_informative)), 1000)\n",
    "qe, pe = ecdf(draws)\n",
    "ax.plot(qe, pe, color=\"magenta\", label=\"Expected CDF Informative Prior\")\n",
    "\n",
    "ax.set_xlim(0, 30000)\n",
    "ax.set_title(\"Bayesian Estimation of Uncertainty in the Posterior Predictive CDF \\n Informative and Non-Informative Priors\", fontsize=20)\n",
    "ax.set_ylabel(\"Fraction Failing\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796debb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot for ax1 (second plot)\n",
    "ax1.hist(hist_data[\"p10\"], bins=30, ec=\"black\", color=\"skyblue\", alpha=0.4, label=\"Uninformative Prior\")\n",
    "ax1.hist(hist_data_info[\"p10\"], bins=30, ec=\"black\", color=\"slateblue\", alpha=0.4, label=\"Informative Prior\")\n",
    "ax1.set_title(\"Distribution of 10% failure Time\", fontsize=20);\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5aee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax2.hist(hist_data[\"p05\"], bins=30, ec=\"black\", color=\"cyan\", alpha=0.4, label=\"Uninformative Prior\")\n",
    "ax2.hist(hist_data_info[\"p05\"], bins=30, ec=\"black\", color=\"pink\", alpha=0.4, label=\"Informative Prior\")\n",
    "ax2.legend()\n",
    "ax2.set_title(\"Distribution of 5% failure Time\", fontsize=20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata_informative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb227fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "from xarray_einstats.stats import XrContinuousRV, XrDiscreteRV\n",
    "\n",
    "\n",
    "def PI_failures(joint_draws, lp, up, n_at_risk):\n",
    "    fit = XrContinuousRV(weibull_min, joint_draws[\"alpha\"], scale=joint_draws[\"beta\"])\n",
    "    rho = fit.cdf(up) - fit.cdf(lp) / (1 - fit.cdf(lp))\n",
    "    lub = XrDiscreteRV(binom, n_at_risk, rho).ppf([0.05, 0.95])\n",
    "    lb, ub = lub.sel(quantile=0.05, drop=True), lub.sel(quantile=0.95, drop=True)\n",
    "    point_prediction = n_at_risk * rho\n",
    "    return xr.Dataset(\n",
    "        {\"rho\": rho, \"n_at_risk\": n_at_risk, \"lb\": lb, \"ub\": ub, \"expected\": point_prediction}\n",
    "    )\n",
    "\n",
    "\n",
    "output_ds = PI_failures(joint_draws, 150, 800, 1300)\n",
    "output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(failures, power):\n",
    "    #Imagined cost function for failing item e.g. refunds required\n",
    "    return np.power(failures, power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(\n",
    "    joint_draws[\"alpha\"],\n",
    "    output_ds[\"expected\"],\n",
    "    c=joint_draws[\"beta\"],\n",
    "    cmap=cm.cool,\n",
    "    alpha=0.3,\n",
    "    label=\"Coloured by function of Beta values\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"Expected Failures\")\n",
    "ax.set_xlabel(\"Alpha\")\n",
    "ax.set_title(\n",
    "    \"Posterior Predictive Expected Failure Count between 100-500 hours \\nas a function of Weibull(alpha, beta)\",\n",
    "    fontsize=20,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax1.hist(\n",
    "    output_ds[\"lb\"],\n",
    "    ec=\"black\",\n",
    "    color=\"slateblue\",\n",
    "    label=\"95% PI Lower Bound on Failure Count\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax1.axvline(output_ds[\"lb\"].mean(), label=\"Expected 95% PI Lower Bound on Failure Count\")\n",
    "ax1.axvline(output_ds[\"ub\"].mean(), label=\"Expected 95% PI Upper Bound on Failure Count\")\n",
    "ax1.hist(\n",
    "    output_ds[\"ub\"],\n",
    "    ec=\"black\",\n",
    "    color=\"cyan\",\n",
    "    label=\"95% PI Upper Bound on Failure Count\",\n",
    "    bins=20,\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax1.hist(\n",
    "    output_ds[\"expected\"], ec=\"black\", color=\"pink\", label=\"Expected Count of Failures\", bins=20\n",
    ")\n",
    "ax1.set_title(\"Uncertainty in the Posterior Prediction Interval of Failure Counts\", fontsize=20)\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a421478",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax2.set_title(\"Expected Costs Distribution(s)  \\nbased on implied Failure counts\", fontsize=20)\n",
    "ax2.hist(\n",
    "    cost_func(output_ds[\"expected\"], 2),\n",
    "    label=\"Cost(failures,2)\",\n",
    "    color=\"royalblue\",\n",
    "    alpha=0.3,\n",
    "    ec=\"black\",\n",
    "    bins=20,\n",
    ")\n",
    "ax2.hist(\n",
    "    cost_func(output_ds[\"expected\"], 2.1),\n",
    "    label=\"Cost(failures,2.1)\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    ec=\"black\",\n",
    "    bins=20,\n",
    ")\n",
    "ax2.set_xlabel(\"$ cost\")\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba92815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with fancy MCMC stuff\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import weibull_min\n",
    "\n",
    "data=y\n",
    "\n",
    "# Fit the Weibull distribution to your dataset\n",
    "shape, loc, scale = weibull_min.fit(data, floc=0)\n",
    "\n",
    "# Calculate the 5% and 10% failure times using the fitted distribution\n",
    "failure_5_percent = weibull_min.ppf(0.05, shape, loc=loc, scale=scale)\n",
    "failure_10_percent = weibull_min.ppf(0.1, shape, loc=loc, scale=scale)\n",
    "\n",
    "print(f\"5% Failure Time: {failure_5_percent}\")\n",
    "print(f\"10% Failure Time: {failure_10_percent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4e2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb790d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ff7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039285b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
